{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "# plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data adjustment and augmentation :\n",
    "\n",
    "## 1 - Size adjust for model input\n",
    "- Adjusting the image to kick away the scale : that ensures that the model will not be trained on the scale position/label/text whatever - We have room to spare since the images are all high res.\n",
    "- The adjusted images will be reduced to a more manageable size to be fed to the model (400px*400px), square crop focused on center.\n",
    "\n",
    "## 2 - Simple 'augmentation' :\n",
    "- The initial image aspect ratio is 4:3 @ 4K. That means the center crop will leave details on the left and right side of the image out of the output.\n",
    "- We can both get that information and augment the size of our dataset while staying meaningful : making a sample on left and right sides of the image makes 1 sample 3 output images.\n",
    "- There doesn't seem to be a constant scale between the images so we might as well get zooms. We  will base our sampling on 400*400px (input size for model), cropping while making sure the average pixel value of the crop is somewhat similar to the initial image.\n",
    "\n",
    "## 3 - Data augmentation :\n",
    "- Will run standard data augmentation techniques to enlarge the dataset while keeping it meaningful and keeping overfitting in mind\n",
    "- Since the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"../imgs/MA184.jpg\"\n",
    "\n",
    "test_image = Image.open(fp=test_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop percentage\n",
    "crop_percentage = 0.075\n",
    "\n",
    "# Adjust box dimensions\n",
    "width, height = test_image.size\n",
    "left = int(width * crop_percentage)\n",
    "upper = int(height * crop_percentage)\n",
    "right = int(width * (1 - crop_percentage))\n",
    "lower = int(height * (1 - crop_percentage))\n",
    "\n",
    "crop_box = (left, upper, right, lower)\n",
    "cropped_image = test_image.crop(crop_box)\n",
    "\n",
    "display(cropped_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Bye scale!</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cropped_image.getbbox())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(images: Image.Image, output_nbr: int = 0, sub_divide: bool = False, augment_subs: bool = False) -> list:\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

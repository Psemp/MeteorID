{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "# plt.style.use('Solarize_Light2')\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.process_batch_images import process_batch\n",
    "from scripts.augment_batch import augment_mp\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data adjustment and augmentation :\n",
    "\n",
    "## 1 - Size adjust for model input\n",
    "- Adjusting the image to kick away the scale : that ensures that the model will not be trained on the scale position/label/text whatever - We have room to spare since the images are all high res.\n",
    "- The adjusted images will be reduced to a more manageable size to be fed to the model (400px*400px), square crop focused on center.\n",
    "\n",
    "## 2 - Simple 'augmentation' :\n",
    "- The initial image aspect ratio is 4:3 @ 4K. That means the center crop will leave details on the left and right side of the image out of the output.\n",
    "- We can both get that information and augment the size of our dataset while staying meaningful : making a sample on left and right sides of the image makes 1 sample 3 output images.\n",
    "- There doesn't seem to be a constant scale between the images so we might as well get zooms. We  will base our sampling on 400*400px (input size for model), cropping while making sure the average pixel value of the crop is somewhat similar to the initial image.\n",
    "\n",
    "## 3 - Data augmentation :\n",
    "- Will run standard data augmentation techniques to enlarge the dataset while keeping it meaningful and keeping overfitting in mind\n",
    "- Since the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"../imgs/MA184.jpg\"\n",
    "\n",
    "test_image = Image.open(fp=test_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop percentage\n",
    "crop_percentage = 0.075\n",
    "\n",
    "# Adjust box dimensions\n",
    "width, height = test_image.size\n",
    "left = int(width * crop_percentage)\n",
    "upper = int(height * crop_percentage)\n",
    "right = int(width * (1 - crop_percentage))\n",
    "lower = int(height * (1 - crop_percentage))\n",
    "\n",
    "crop_box = (left, upper, right, lower)\n",
    "cropped_image = test_image.crop(crop_box)\n",
    "\n",
    "display(cropped_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Bye scale!</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cropped_image.getbbox())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_scale(image, crop_percentage = 0.075):\n",
    "\n",
    "    # Adjust box dimensions\n",
    "    width, height = image.size\n",
    "    left = int(width * crop_percentage)\n",
    "    upper = int(height * crop_percentage)\n",
    "    right = int(width * (1 - crop_percentage))\n",
    "    lower = int(height * (1 - crop_percentage))\n",
    "\n",
    "    crop_box = (left, upper, right, lower)\n",
    "    cropped_image = image.crop(crop_box)\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def resize_center(image, output_size=(400, 400)):\n",
    "    width, height = image.size\n",
    "\n",
    "    new_width = min(width, height)\n",
    "    left = (width - new_width) / 2\n",
    "    top = (height - new_width) / 2\n",
    "    right = (width + new_width) / 2\n",
    "    bottom = (height + new_width) / 2\n",
    "    \n",
    "    # crop @ center\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    # resize at output_size resolution\n",
    "    resized_image = cropped_image.resize(output_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def crop_strips(image, strip_width=800):\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate the center square size\n",
    "    center_width = width - 2 * strip_width\n",
    "    left_crop = strip_width\n",
    "    right_crop = width - strip_width\n",
    "    \n",
    "    # Crop the left and right strips\n",
    "    left_strip = image.crop((0, 0, left_crop, height))\n",
    "    right_strip = image.crop((right_crop, 0, width, height))\n",
    "    \n",
    "    return left_strip, right_strip\n",
    "\n",
    "\n",
    "def get_average_grid_px(image):\n",
    "    width, height = image.size\n",
    "    grid_size = 3  # 3x3 grid\n",
    "\n",
    "    # Ensure the image is square\n",
    "    assert width == height, \"The image must be square.\"\n",
    "\n",
    "    # Step size determination\n",
    "    step_size = width // grid_size\n",
    "\n",
    "    grid_avg_values = []\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            # Grid cell's BBOX\n",
    "            left = i * step_size\n",
    "            top = j * step_size\n",
    "            right = left + step_size\n",
    "            bottom = top + step_size\n",
    "\n",
    "            # Crop the grid\n",
    "            grid_cell = image.crop((left, top, right, bottom))\n",
    "\n",
    "            # Averages the pixel value of each cell\n",
    "            np_grid_cell = np.array(grid_cell)\n",
    "            avg_r = np.mean(np_grid_cell[:, :, 0])\n",
    "            avg_g = np.mean(np_grid_cell[:, :, 1])\n",
    "            avg_b = np.mean(np_grid_cell[:, :, 2])\n",
    "\n",
    "            # Append the average values as a tuple\n",
    "            grid_avg_values.append((avg_r, avg_g, avg_b))\n",
    "\n",
    "    return grid_avg_values\n",
    "\n",
    "\n",
    "def get_crops_staircase_pattern(strip, crop_size=(400, 400)):\n",
    "    width, height = strip.size\n",
    "    crop_width, crop_height = crop_size\n",
    "\n",
    "    crops = []\n",
    "    \n",
    "    # Iterate over the height of the strip\n",
    "    for y in range(0, height - crop_height + 1, crop_height):\n",
    "        # Top left crop\n",
    "        left_crop = strip.crop((0, y, crop_width, y + crop_height))\n",
    "        crops.append(left_crop)\n",
    "        \n",
    "        # Top right crop (aligned to the right edge)\n",
    "        if width > crop_width:\n",
    "            right_crop = strip.crop((width - crop_width, y, width, y + crop_height))\n",
    "            crops.append(right_crop)\n",
    "    \n",
    "    # Handle the last line if there's at least 100px remaining\n",
    "    remaining_height = height % crop_height\n",
    "    if remaining_height >= 100:\n",
    "        y = height - crop_height\n",
    "        left_crop = strip.crop((0, y, crop_width, height))\n",
    "        crops.append(left_crop)\n",
    "\n",
    "        if width > crop_width:\n",
    "            right_crop = strip.crop((width - crop_width, y, width, height))\n",
    "            crops.append(right_crop)\n",
    "    \n",
    "    return crops\n",
    "\n",
    "\n",
    "def calculate_difference(original_values, crop_values):\n",
    "    # Sum of absolute differences across RGB channels for each grid point\n",
    "    return np.sum(np.abs(np.array(original_values) - np.array(crop_values)))\n",
    "\n",
    "\n",
    "def get_best_crop(original_image, strip, crop_size = (400, 400)):\n",
    "\n",
    "    pixel_average_original = get_average_grid_px(image=original_image)\n",
    "\n",
    "    crops = get_crops_staircase_pattern(strip=strip, crop_size=crop_size)\n",
    "\n",
    "    best_crop = None\n",
    "    best_delta = float(\"inf\")\n",
    "\n",
    "    for crop in crops:\n",
    "        delta = calculate_difference(original_values=pixel_average_original, crop_values=get_average_grid_px(image=crop))\n",
    "        if delta < best_delta:\n",
    "            best_delta = delta\n",
    "            best_crop = crop\n",
    "\n",
    "    return best_crop\n",
    "\n",
    "\n",
    "def process_image(image_path: str, save_directory: str) -> None:\n",
    "    # crop to remove scale :\n",
    "    image = Image.open(fp=image_path)\n",
    "    image_name = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    image = rm_scale(image=image)\n",
    "\n",
    "    # center main image\n",
    "    centered_image = resize_center(image=image)\n",
    "\n",
    "    left_strip, right_strip = crop_strips(image=image)\n",
    "\n",
    "    best_left = get_best_crop(original_image=centered_image, strip=left_strip)\n",
    "    best_right = get_best_crop(original_image=centered_image, strip=right_strip)\n",
    "\n",
    "    rotate_left = np.random.choice(np.arange(0, 360, 90))\n",
    "    rotate_right = np.random.choice(np.arange(0, 360, 90))\n",
    "\n",
    "    if rotate_left != 0:\n",
    "        best_left = best_left.rotate(rotate_left)\n",
    "\n",
    "    if rotate_right != 0:\n",
    "        best_right = best_right.rotate(rotate_right)\n",
    "\n",
    "    # Saving :\n",
    "    if save_directory[-1] != \"/\":\n",
    "        save_directory = save_directory + \"/\"\n",
    "\n",
    "    best_left.save(fp=save_directory + image_name + \"l\" + \".jpg\", format=\"JPEG\")\n",
    "    best_right.save(fp=save_directory + image_name + \"r\" + \".jpg\", format=\"JPEG\")\n",
    "    centered_image.save(fp=save_directory + image_name + \"c\" + \".jpg\", format=\"JPEG\")\n",
    "\n",
    "\n",
    "def augment(images: Image.Image, output_nbr: int = 0, sub_divide: bool = False, augment_subs: bool = False) -> list:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_image = resize_center(image=cropped_image)\n",
    "display(centered_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop, right_crop = crop_strips(image=cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(left_crop.getbbox())\n",
    "display(left_crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(right_crop.getbbox())\n",
    "display(right_crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_px_test_center = get_average_grid_px(image=resize_center(image=cropped_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crops = get_crops_staircase_pattern(strip=left_crop)\n",
    "right_crops = get_crops_staircase_pattern(strip=right_crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crop in left_crops:\n",
    "    display(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crop in right_crops:\n",
    "    display(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_best = get_best_crop(original_image=centered_image, strip=left_crop)\n",
    "display(left_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_best = get_best_crop(original_image=centered_image, strip=right_crop)\n",
    "display(right_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mp image processing :\n",
    "\n",
    "image_dir = \"../imgs/\"\n",
    "save_dir = \"../data/processed_images/\"\n",
    "\n",
    "process_batch(image_directory=image_dir, save_directory=save_dir, max_workers=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations on minority classes :\n",
    "- Flip\n",
    "- Random Crop\n",
    "- Random rotate\n",
    "- Scaling\n",
    "\n",
    "High minority classes (above 100) will have one augment\n",
    "Mid minority will have 2\n",
    "Low minority will have 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load updated df :\n",
    "df = pd.read_pickle(\"../data/work_met_img_type_2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_count(df):\n",
    "    df_exploded = df.explode(\"images\")\n",
    "    \n",
    "    image_counts = df_exploded[\"mtype\"].value_counts()\n",
    "    \n",
    "    return image_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_count(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_mp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def update_dataframe_with_augmented_images(df, augmented_images_dir):\n",
    "    \"\"\"\n",
    "    Updates the DataFrame to include augmented images with their corresponding work_name and mtype.\n",
    "\n",
    "    :param df: Original DataFrame with columns 'work_name', 'mtype', 'images'\n",
    "    :param augmented_images_dir: Directory containing augmented images\n",
    "    :return: The updated DataFrame (modified in place)\n",
    "    \"\"\"\n",
    "    # Ensure 'images' column is a list\n",
    "    df['images'] = df['images'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "    # Collect all augmented image filenames\n",
    "    augmented_image_files = [\n",
    "        f for f in os.listdir(augmented_images_dir)\n",
    "        if os.path.isfile(os.path.join(augmented_images_dir, f))\n",
    "    ]\n",
    "\n",
    "    # For quick access, create a set of augmented image filenames\n",
    "    augmented_image_set = set(augmented_image_files)\n",
    "\n",
    "    # For each row in df, update the 'images' list\n",
    "    for index, row in df.iterrows():\n",
    "        original_images = row['images']\n",
    "        new_images = []\n",
    "        for orig_image_name in original_images:\n",
    "            # Remove extension and directory from original image name\n",
    "            orig_image_base = os.path.splitext(os.path.basename(orig_image_name))[0]\n",
    "            # Find augmented images that start with the original image base name followed by an underscore\n",
    "            matching_augmented_images = [\n",
    "                aug_image for aug_image in augmented_image_set\n",
    "                if aug_image.startswith(orig_image_base + '_')\n",
    "            ]\n",
    "            new_images.extend(matching_augmented_images)\n",
    "        # Add the matching augmented images to the 'images' list for this row\n",
    "        df.at[index, 'images'].extend(new_images)\n",
    "\n",
    "    # Remove duplicates from 'images' lists\n",
    "    df['images'] = df['images'].apply(lambda x: list(set(x)))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Assuming df is already loaded and augmented images are in 'augmented_images_dir'\n",
    "augmented_images_dir = \"../data/processed_images/\"\n",
    "\n",
    "\n",
    "df_augment = update_dataframe_with_augmented_images(df, augmented_images_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augment.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_count(df=df_augment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
